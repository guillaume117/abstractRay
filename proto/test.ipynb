{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guillaume/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-07-08 17:13:14,521\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('app/src')\n",
    "sys.path.append('./src')\n",
    "from util import sparse_tensor_stats\n",
    "\n",
    "\n",
    "from sparse_evaluation_4 import SparseEvaluation  \n",
    "from zono_sparse_gen import ZonoSparseGeneration\n",
    "\n",
    "from abstract_relu import AbstractReLU\n",
    "from sparse_addition_2 import SparseAddition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.4162, 0.0000, 1.2699]])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1,3)\n",
    "input = torch.where(input>0,input,0)\n",
    "print(input)\n",
    "_, new_sparse = ZonoSparseGeneration(input,from_trash=True,start_index=5).total_zono()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[5, 6],\n",
       "                       [0, 2]]),\n",
       "       values=tensor([2.4162, 1.2699]),\n",
       "       size=(7, 3), nnz=2, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000],\n",
       "        [2.4162, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 1.2699]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sparse.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with: 4 CPUs\n",
      "Running with: 1 GPUs\n",
      "Hello from MyClass\n",
      "<__main__.DecoratedClass._create_decorated_class.<locals>.Decorated object at 0x72155eee4370>\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "# Simuler ray.remote pour cet exemple\n",
    "def remote_decorator(num_gpus=None, num_cpus=None):\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            resources = []\n",
    "            if num_gpus is not None:\n",
    "                resources.append(f\"{num_gpus} GPUs\")\n",
    "            if num_cpus is not None:\n",
    "                resources.append(f\"{num_cpus} CPUs\")\n",
    "            print(f\"Running with: {', '.join(resources)}\")\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "class DecoratedClass:\n",
    "    def __init__(self, cls, gpu_decorator, cpu_decorator):\n",
    "        self.decorated_class = self._create_decorated_class(cls, gpu_decorator, cpu_decorator)\n",
    "\n",
    "    def _create_decorated_class(self, cls, gpu_decorator, cpu_decorator):\n",
    "        class Decorated(cls):\n",
    "            pass\n",
    "        \n",
    "        for attr_name in dir(cls):\n",
    "            attr = getattr(cls, attr_name)\n",
    "            if callable(attr) and not attr_name.startswith(\"__\"):\n",
    "                decorated_method = gpu_decorator(attr)\n",
    "                decorated_method = cpu_decorator(decorated_method)\n",
    "                setattr(Decorated, attr_name, decorated_method)\n",
    "                \n",
    "        return Decorated\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.decorated_class(*args, **kwargs)\n",
    "\n",
    "# Exemple de décorateurs\n",
    "gpu_decorator = remote_decorator(num_gpus=1)\n",
    "cpu_decorator = remote_decorator(num_cpus=4)\n",
    "\n",
    "# Utilisation\n",
    "DecoratedMyClass = DecoratedClass(MyClass, gpu_decorator, cpu_decorator)\n",
    "\n",
    "# Instanciation et appel de la méthode décorée\n",
    "instance = DecoratedMyClass()\n",
    "print(instance.my_method())\n",
    "print(instance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 15:12:17,051\tINFO worker.py:1753 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(autoscaler +34m2s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "\u001b[33m(autoscaler +34m2s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 2.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m worker \u001b[38;5;241m=\u001b[39m create_sparse_worker(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparam1_value\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparam2_value\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Appelez une méthode de la classe\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ray/_private/auto_init_hook.py:21\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     20\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ray/_private/worker.py:2613\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2608\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid type of object refs, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(object_refs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, is given. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2609\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject_refs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must either be an ObjectRef or a list of ObjectRefs. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2610\u001b[0m     )\n\u001b[1;32m   2612\u001b[0m \u001b[38;5;66;03m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[39;00m\n\u001b[0;32m-> 2613\u001b[0m values, debugger_breakpoint \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2614\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(values):\n\u001b[1;32m   2615\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, RayError):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ray/_private/worker.py:840\u001b[0m, in \u001b[0;36mWorker.get_objects\u001b[0;34m(self, object_refs, timeout)\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    835\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to call `get` on the value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobject_ref\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    836\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich is not an ray.ObjectRef.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    837\u001b[0m         )\n\u001b[1;32m    839\u001b[0m timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 840\u001b[0m data_metadata_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_objects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_task_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    845\u001b[0m debugger_breakpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, metadata \u001b[38;5;129;01min\u001b[39;00m data_metadata_pairs:\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:3485\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.get_objects\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:571\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "# Supposons que votre classe SparseWorker ressemble à ceci :\n",
    "class SparseWorker:\n",
    "    def __init__(self, param1, param2):\n",
    "        self.param1 = param1\n",
    "        self.param2 = param2\n",
    "\n",
    "    def work(self):\n",
    "        return self.param1 + self.param2\n",
    "\n",
    "# Fonction pour instancier la classe avec des paramètres dynamiques\n",
    "def create_sparse_worker(num_cpus,num_gpus, *args, **kwargs):\n",
    "    SparseWorkerRemote = ray.remote(num_cpus=num_cpus,num_gpus=num_gpus)(SparseWorker)\n",
    "    return SparseWorkerRemote.remote(*args, **kwargs)\n",
    "\n",
    "# Initialiser Ray\n",
    "ray.init()\n",
    "\n",
    "# Créez une instance de SparseWorker avec un nombre personnalisé de CPUs\n",
    "worker = create_sparse_worker(2,1, \"param1_value\", \"param2_value\")\n",
    "\n",
    "# Appelez une méthode de la classe\n",
    "result = ray.get(worker.work.remote())\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.sparse import FloatTensor\n",
    "from typing import List, Union, Tuple, Callable\n",
    "\n",
    "# Add paths for imports\n",
    "sys.path.append('app/src')\n",
    "sys.path.append('./src')\n",
    "\n",
    "\n",
    "def list_of_shape(tensor: torch.Tensor) -> List[int]:\n",
    "    \"\"\"Returns the shape of a tensor as a list.\"\"\"\n",
    "    tensor.clone().detach()\n",
    "    return list(tensor.shape)\n",
    "\n",
    "class ZonoSparseGeneration:\n",
    "    \"\"\"This class generates a sparse representation of an abstract domain.\"\"\"\n",
    "    \n",
    "    def __init__(self, input: FloatTensor, noise_intensity : Union[float, torch.Tensor]=0, noise_type: str = 'additive', \n",
    "                 indices=None, from_trash=False, start_index=None):\n",
    "        self.input = input.to('cpu')\n",
    "        self.noise_intensity = torch.tensor(noise_intensity).to('cpu')\n",
    "        self.noise_type = noise_type\n",
    "        self.input_shape = list_of_shape(input)\n",
    "        self.indices = indices\n",
    "        self.from_trash = from_trash\n",
    "        self.start_index = start_index\n",
    "\n",
    "    def total_zono(self):\n",
    "        \"\"\"Generates a sparse zonotope.\"\"\"\n",
    "        if not self.from_trash:\n",
    "            dim_input = torch.tensor(self.input_shape).numel()\n",
    "\n",
    "            if dim_input == 1:\n",
    "                global_storage = {'indices': [], 'values': []}\n",
    "\n",
    "                if self.indices is None:\n",
    "                    num_elements = self.input_shape[0]\n",
    "                    self.indices = torch.arange(1, num_elements, 1)\n",
    "                else:\n",
    "                    self.indices = self.indices.to('cpu')\n",
    "                    #self.indices = torch.tensor(self.indices)\n",
    "                    num_elements = self.indices.numel()\n",
    "\n",
    "                if len(self.noise_intensity.flatten()) == 1:\n",
    "                    self.noise_intensity = self.noise_intensity * torch.ones_like(self.indices)\n",
    "                else:\n",
    "                    print(self.noise_intensity.size())\n",
    "                    print(self.indices.size())\n",
    "                    assert self.noise_intensity.size() == self.indices.size(), 'the length of noise intensity must be one or equal to indices shape'\n",
    "\n",
    "                for i in range(num_elements):\n",
    "                    global_storage['indices'].append([self.indices[i], self.indices[i]])\n",
    "                    global_storage['values'].append(self.noise_intensity[i])\n",
    "\n",
    "                indice_tensor = torch.tensor(global_storage['indices'], dtype=torch.int32).t()\n",
    "                values_tensor = torch.tensor(global_storage['values'], dtype=torch.float32)\n",
    "                sparse_zonotope = torch.sparse_coo_tensor(indice_tensor, values_tensor, size=(self.input_shape[0], self.input_shape[0])).coalesce()\n",
    "\n",
    "                return self.input, sparse_zonotope.to_dense()\n",
    "\n",
    "            if dim_input == 2:\n",
    "                self.input = self.input.unsqueeze(0)\n",
    "                self.input_shape = list_of_shape(self.input)\n",
    "            \n",
    "            if dim_input == 4:\n",
    "                self.input = self.input.squeeze(0)\n",
    "                print(\"WARNING: Trying to generate abstract Sparse tensor from a batch, only the first element will be used\")\n",
    "                self.input_shape = list_of_shape(self.input)\n",
    "\n",
    "            if self.indices is None:\n",
    "                assert len(self.noise_intensity.flatten()) == 1, 'Shape of noise and indices do not match'\n",
    "                num_elements = self.input_shape[0]\n",
    "                self.indices = torch.arange(1, num_elements, 1)\n",
    "                global_storage = {'indices': [], 'values': []}\n",
    "                num_elements = self.input_shape[0] * self.input_shape[1] * self.input_shape[2]\n",
    "\n",
    "                for i in range(num_elements):\n",
    "                    dim_3 = i // (self.input_shape[1] * self.input_shape[2])\n",
    "                    rem = i % (self.input_shape[1] * self.input_shape[2])\n",
    "                    dim_1 = rem // self.input_shape[1]\n",
    "                    dim_2 = rem % self.input_shape[2]\n",
    "                    global_storage['indices'].append([i, dim_3, dim_1, dim_2])\n",
    "                    global_storage['values'].append(self.noise_intensity)\n",
    "\n",
    "                indice_tensor = torch.tensor(global_storage['indices'], dtype=torch.int32).t()\n",
    "                values_tensor = torch.tensor(global_storage['values'], dtype=torch.float32)\n",
    "                sparse_zonotope = torch.sparse_coo_tensor(indice_tensor, values_tensor, size=(num_elements, self.input_shape[0], self.input_shape[1], self.input_shape[2])).coalesce()\n",
    "\n",
    "            else:\n",
    "                self.indices = torch.tensor(self.indices).to('cpu')\n",
    "                #assert len(self.indices) == len(self.noise_intensity), 'Length of Noise_intensity and indices mismatch'\n",
    "                global_storage = {'indices': [], 'values': []}\n",
    "                num_elements = len(self.indices)\n",
    "\n",
    "                for i in range(num_elements):\n",
    "                    if len(self.indices[i]) == 2:\n",
    "                        global_storage['indices'].append(torch.cat((torch.tensor([i, 0]), self.indices[i])).tolist())\n",
    "                    else:\n",
    "                        global_storage['indices'].append(torch.cat((torch.tensor([i]), self.indices[i])).tolist())\n",
    "                    global_storage['values'].append(self.noise_intensity[i])\n",
    "\n",
    "                indice_tensor = torch.tensor(global_storage['indices'], dtype=torch.int32).t()\n",
    "                values_tensor = torch.tensor(global_storage['values'], dtype=torch.float32)\n",
    "                print(indice_tensor)\n",
    "                print(values_tensor)\n",
    "\n",
    "                sparse_zonotope = torch.sparse_coo_tensor(indice_tensor, values_tensor, size=(num_elements, self.input_shape[0], self.input_shape[1], self.input_shape[2])).coalesce()\n",
    "\n",
    "            return self.input, sparse_zonotope\n",
    "\n",
    "        if self.from_trash:\n",
    "            if not self.start_index:\n",
    "                print('Warning, start_index is 0, should start at the depth of abstract domain')\n",
    "                self.start_index = 0\n",
    "\n",
    "            global_storage = {'indices': [], 'values': []}\n",
    "            indices = torch.nonzero(self.input)\n",
    "            if len(indices)==0: \n",
    "                return self.input, None\n",
    "          \n",
    "\n",
    "            for i, indice in enumerate(indices):\n",
    "                sparse_indice = torch.cat((torch.tensor([i + self.start_index]), indice[1:])).tolist()\n",
    "                global_storage['indices'].append(sparse_indice)\n",
    "                global_storage['values'].append(self.input[tuple(indice.tolist())])\n",
    "            \n",
    "            indice_tensor = torch.tensor(global_storage['indices'], dtype=torch.int32).t()\n",
    "            values_tensor = torch.tensor(global_storage['values'], dtype=torch.float32)\n",
    "            dim = tuple(torch.cat((torch.tensor([len(indices)+self.start_index]), torch.tensor(list_of_shape(self.input.squeeze(0))))))\n",
    "\n",
    "            sparse_zonotope = torch.sparse_coo_tensor(indice_tensor, values_tensor, size=dim).coalesce()\n",
    "\n",
    "            return self.input, sparse_zonotope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Trying to generate abstract Sparse tensor from a batch, only the first element will be used\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 0,  0,  0,  0],\n",
      "        [ 0,  0,  0,  1],\n",
      "        ...,\n",
      "        [ 0,  2, 23, 21],\n",
      "        [ 0,  2, 23, 22],\n",
      "        [ 0,  2, 23, 23]], dtype=torch.int32)\n",
      "tensor([ 0.8147,  0.4032, -1.0225, -0.2999])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2764178/3528852022.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.noise_intensity = torch.tensor(noise_intensity).to('cpu')\n",
      "/tmp/ipykernel_2764178/3528852022.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.indices = torch.tensor(self.indices).to('cpu')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "number of dimensions must be sparse_dim (1729) + dense_dim (0), but got 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m test  \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m24\u001b[39m,\u001b[38;5;241m24\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m _,zonotop \u001b[38;5;241m=\u001b[39m \u001b[43mZonoSparseGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_intensity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_zono\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 110\u001b[0m, in \u001b[0;36mZonoSparseGeneration.total_zono\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;28mprint\u001b[39m(indice_tensor)\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28mprint\u001b[39m(values_tensor)\n\u001b[0;32m--> 110\u001b[0m         sparse_zonotope \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse_coo_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindice_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_elements\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcoalesce()\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput, sparse_zonotope\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_trash:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: number of dimensions must be sparse_dim (1729) + dense_dim (0), but got 4"
     ]
    }
   ],
   "source": [
    "test  = torch.randn(1,3,24,24)\n",
    "_,zonotop = ZonoSparseGeneration(input=test, noise_intensity=test.to_sparse().values(),indices = test.to_sparse().indices()).total_zono()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZonoSparseGeneration:\n",
    "    def __init__(self):\n",
    "        self.global_storage = {}\n",
    "        self.global_storage['indices'] =[]\n",
    "        self.global_storage['values'] = []\n",
    "        pass\n",
    "    def zono_from_tensor(self,noise_intensity):\n",
    "        assert noise_intensity.size(0)==1,'First dimension size must be 1'\n",
    "        noise_intensity = noise_intensity.to_sparse()\n",
    "        noise_intensity.indices()[0] = torch.arange(noise_intensity._nnz())\n",
    "        size =(noise_intensity._nnz(),*noise_intensity.size()[1:])\n",
    "\n",
    "        noise_intensity = torch.sparse_coo_tensor(noise_intensity.indices(),noise_intensity.values(),size = size)\n",
    "        noise_intensity.coalesce()\n",
    "\n",
    "        return(noise_intensity)\n",
    "\n",
    "    def zono_from_noise_level_and_tensor(self,noise_level,tensor):\n",
    "        \n",
    "        noise_intensity = noise_level*torch.ones_like(tensor)\n",
    "        zonotope = self.zono_from_tensor(noise_intensity=noise_intensity)\n",
    "        return zonotope\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "         \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "tensor([[-0.3511,  0.0000,  0.0000],\n",
      "        [ 0.0000, -0.5359,  0.0000],\n",
      "        [ 0.0000,  0.0000, -0.6982]])\n"
     ]
    }
   ],
   "source": [
    "test = ZonoSparseGeneration().zono_from_tensor( noise_intensity=torch.randn(1,3\n",
    "                                                                           ))\n",
    "print(test.to_dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "tensor([[0.0100, 0.0000],\n",
      "        [0.0000, 0.0100]])\n"
     ]
    }
   ],
   "source": [
    "test_2 = ZonoSparseGeneration().zono_from_noise_level_and_tensor(noise_level=0.01,tensor=torch.randn(1,2))\n",
    "print(test_2.to_dense())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
