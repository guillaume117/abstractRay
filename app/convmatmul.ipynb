{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from matrix multiplication:\n",
      "tensor([[[[-0.2798, -0.0576,  0.4760, -0.0022,  0.5965],\n",
      "          [-0.3831, -0.6861,  0.1310, -0.2115,  0.6901],\n",
      "          [ 0.1581, -0.3168, -0.4913, -0.9078, -0.0365],\n",
      "          [-0.1768, -0.2058, -1.0859, -0.3986, -0.3868],\n",
      "          [-0.3603, -0.2312, -1.2773, -0.3161,  0.3108]],\n",
      "\n",
      "         [[ 0.1639,  0.0842,  0.9165, -0.2983, -0.2242],\n",
      "          [-0.0229, -0.0566, -0.1032, -0.2204, -0.1244],\n",
      "          [ 0.2391,  0.2545,  0.6743, -0.2300, -0.2058],\n",
      "          [-0.1515,  0.7881,  0.5873, -0.8179, -0.1022],\n",
      "          [ 0.1383, -0.2363, -0.0521, -0.9489, -0.5987]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Output from standard convolution:\n",
      "tensor([[[[-0.4578, -0.2355,  0.2980, -0.1801,  0.4185],\n",
      "          [-0.5611, -0.8640, -0.0470, -0.3895,  0.5121],\n",
      "          [-0.0199, -0.4947, -0.6693, -1.0858, -0.2144],\n",
      "          [-0.3547, -0.3838, -1.2639, -0.5765, -0.5648],\n",
      "          [-0.5383, -0.4092, -1.4553, -0.4941,  0.1328]],\n",
      "\n",
      "         [[ 0.2126,  0.1329,  0.9652, -0.2495, -0.1755],\n",
      "          [ 0.0258, -0.0079, -0.0545, -0.1717, -0.0757],\n",
      "          [ 0.2878,  0.3033,  0.7230, -0.1813, -0.1571],\n",
      "          [-0.1028,  0.8369,  0.6361, -0.7692, -0.0535],\n",
      "          [ 0.1870, -0.1876, -0.0034, -0.9002, -0.5500]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "Difference between outputs: tensor(0.1779, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def conv2d_to_matmul(input, conv_layer):\n",
    "    # Extract Conv2D parameters\n",
    "    in_channels = conv_layer.in_channels\n",
    "    out_channels = conv_layer.out_channels\n",
    "    kernel_size = conv_layer.kernel_size\n",
    "    stride = conv_layer.stride\n",
    "    padding = conv_layer.padding\n",
    "    dilation = conv_layer.dilation\n",
    "\n",
    "    # Unfold (im2col) the input tensor\n",
    "    input_unf = F.unfold(input, kernel_size=kernel_size, dilation=dilation, padding=padding, stride=stride)\n",
    "\n",
    "    # Reshape the weight tensor of the conv layer\n",
    "    weight = conv_layer.weight.view(out_channels, -1)\n",
    "\n",
    "    # Perform matrix multiplication\n",
    "    output_unf = weight @ input_unf\n",
    "\n",
    "    # Reshape the output to the correct dimensions\n",
    "    output_height = (input.size(2) + 2*padding[0] - dilation[0] * (kernel_size[0] - 1) - 1) // stride[0] + 1\n",
    "    output_width = (input.size(3) + 2*padding[1] - dilation[1] * (kernel_size[1] - 1) - 1) // stride[1] + 1\n",
    "    output = output_unf.view(1, out_channels, output_height, output_width)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Example usage\n",
    "input = torch.randn(1, 3, 5, 5)  # Batch size 1, 3 channels, 5x5 image\n",
    "conv_layer = nn.Conv2d(in_channels=3, out_channels=2, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# Get the output using the conv2d_to_matmul function\n",
    "output = conv2d_to_matmul(input, conv_layer)\n",
    "\n",
    "# Verify against the standard convolution\n",
    "conv_output = conv_layer(input)\n",
    "\n",
    "print(\"Output from matrix multiplication:\")\n",
    "print(output)\n",
    "\n",
    "print(\"Output from standard convolution:\")\n",
    "print(conv_output)\n",
    "\n",
    "# Verify that the outputs are the same\n",
    "print(\"Difference between outputs:\", torch.abs(output - conv_output).max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from matrix multiplication:\n",
      "tensor([[[[ 0.0647, -0.8771,  0.1172, -0.5919, -0.2884],\n",
      "          [-0.3678,  0.0288, -0.7642,  0.3269,  0.8414],\n",
      "          [-0.6333,  0.6534, -0.2398, -0.1189,  0.4273],\n",
      "          [ 0.0820, -0.0814,  0.0694, -0.1249, -0.5725],\n",
      "          [ 0.0334, -0.4556, -0.1662,  0.8488, -0.5382]],\n",
      "\n",
      "         [[ 0.1186,  0.5653, -0.8192,  0.3583,  0.0349],\n",
      "          [ 0.4989,  0.4936,  1.6190,  0.3322,  0.5158],\n",
      "          [ 0.5491, -0.8562,  0.6179, -0.2699, -0.4139],\n",
      "          [-0.1246,  0.0294,  0.9565, -0.3862,  0.1130],\n",
      "          [ 0.3713,  0.5061, -0.0591,  0.4057,  0.5807]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Output from standard convolution:\n",
      "tensor([[[[ 0.0647, -0.8771,  0.1172, -0.5919, -0.2884],\n",
      "          [-0.3678,  0.0288, -0.7642,  0.3269,  0.8414],\n",
      "          [-0.6333,  0.6534, -0.2398, -0.1189,  0.4273],\n",
      "          [ 0.0820, -0.0814,  0.0694, -0.1249, -0.5725],\n",
      "          [ 0.0334, -0.4556, -0.1662,  0.8488, -0.5382]],\n",
      "\n",
      "         [[ 0.1186,  0.5653, -0.8192,  0.3583,  0.0349],\n",
      "          [ 0.4989,  0.4936,  1.6190,  0.3322,  0.5158],\n",
      "          [ 0.5491, -0.8562,  0.6179, -0.2699, -0.4139],\n",
      "          [-0.1246,  0.0294,  0.9565, -0.3862,  0.1130],\n",
      "          [ 0.3713,  0.5061, -0.0591,  0.4057,  0.5807]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "Difference between outputs: tensor(1.1921e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def conv2d_to_matmul(input, conv_layer):\n",
    "    # Extract Conv2D parameters\n",
    "    in_channels = conv_layer.in_channels\n",
    "    out_channels = conv_layer.out_channels\n",
    "    kernel_size = conv_layer.kernel_size\n",
    "    stride = conv_layer.stride\n",
    "    padding = conv_layer.padding\n",
    "    dilation = conv_layer.dilation\n",
    "\n",
    "    # Unfold (im2col) the input tensor\n",
    "    input_unf = F.unfold(input, kernel_size=kernel_size, dilation=dilation, padding=padding, stride=stride)\n",
    "\n",
    "    # Reshape the weight tensor of the conv layer\n",
    "    weight = conv_layer.weight.view(out_channels, -1)\n",
    "\n",
    "    # Perform matrix multiplication\n",
    "    output_unf = weight @ input_unf\n",
    "\n",
    "    # Add the bias\n",
    "    if conv_layer.bias is not None:\n",
    "        output_unf += conv_layer.bias.unsqueeze(1)\n",
    "\n",
    "    # Reshape the output to the correct dimensions\n",
    "    output_height = (input.size(2) + 2*padding[0] - dilation[0] * (kernel_size[0] - 1) - 1) // stride[0] + 1\n",
    "    output_width = (input.size(3) + 2*padding[1] - dilation[1] * (kernel_size[1] - 1) - 1) // stride[1] + 1\n",
    "    output = output_unf.view(1, out_channels, output_height, output_width)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Example usage\n",
    "input = torch.randn(1, 3, 5, 5)  # Batch size 1, 3 channels, 5x5 image\n",
    "conv_layer = nn.Conv2d(in_channels=3, out_channels=2, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# Get the output using the conv2d_to_matmul function\n",
    "output = conv2d_to_matmul(input, conv_layer)\n",
    "\n",
    "# Verify against the standard convolution\n",
    "conv_output = conv_layer(input)\n",
    "\n",
    "print(\"Output from matrix multiplication:\")\n",
    "print(output)\n",
    "\n",
    "print(\"Output from standard convolution:\")\n",
    "print(conv_output)\n",
    "\n",
    "# Verify that the outputs are the same\n",
    "print(\"Difference between outputs:\", torch.abs(output - conv_output).max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from matrix multiplication:\n",
      "tensor([[[[-4.0380e-01, -3.1406e-01, -4.7838e-01,  ..., -1.5355e-01,\n",
      "            4.0880e-01,  2.2182e-01],\n",
      "          [ 4.4625e-01,  5.9604e-01, -4.1285e-01,  ...,  1.6947e-01,\n",
      "           -6.5281e-03, -8.1054e-01],\n",
      "          [ 3.7832e-01, -1.7156e-01, -4.7183e-02,  ...,  4.3828e-01,\n",
      "           -2.5419e-01,  1.3473e+00],\n",
      "          ...,\n",
      "          [-5.4286e-01,  1.8729e-03,  1.5082e+00,  ..., -4.5478e-01,\n",
      "           -4.7381e-01,  3.9000e-01],\n",
      "          [ 4.4608e-01, -9.0825e-01, -7.6615e-01,  ..., -3.3419e-01,\n",
      "           -7.8931e-01,  7.2388e-02],\n",
      "          [-3.6955e-01,  3.7082e-01,  2.9245e-01,  ...,  6.5912e-01,\n",
      "            2.9895e-01,  2.3225e-01]],\n",
      "\n",
      "         [[ 4.0400e-01, -1.4922e-01,  4.4431e-01,  ...,  4.1689e-01,\n",
      "            2.9981e-01, -7.6605e-01],\n",
      "          [ 8.3809e-01,  5.0024e-01,  1.0052e+00,  ...,  2.5175e-02,\n",
      "           -6.3276e-02,  5.1493e-01],\n",
      "          [-3.4004e-01,  1.3410e+00,  5.6880e-01,  ...,  1.9813e-01,\n",
      "            4.7307e-01,  2.9385e-01],\n",
      "          ...,\n",
      "          [-6.2042e-01,  6.7714e-01,  8.0907e-01,  ..., -2.1155e-01,\n",
      "            4.3821e-01, -8.0160e-02],\n",
      "          [-2.2440e-01,  1.9800e-01, -2.7004e-01,  ...,  8.1119e-01,\n",
      "            3.7719e-01, -7.6588e-01],\n",
      "          [-3.7101e-01,  6.2999e-01,  4.7059e-01,  ...,  3.4798e-01,\n",
      "            5.2222e-01,  2.5050e-01]],\n",
      "\n",
      "         [[-1.1212e-01, -6.2471e-01, -2.5591e-01,  ...,  3.9001e-01,\n",
      "            4.7703e-01, -3.0788e-01],\n",
      "          [ 4.3852e-01,  5.6115e-01,  2.3291e-01,  ..., -8.2766e-01,\n",
      "            7.3046e-01, -1.5826e-01],\n",
      "          [ 3.7738e-01,  6.0093e-01,  1.7431e-01,  ...,  7.0693e-01,\n",
      "            8.0548e-01,  2.9699e-01],\n",
      "          ...,\n",
      "          [ 5.9608e-01,  1.0078e-01,  3.0823e-01,  ..., -5.7602e-01,\n",
      "           -1.1783e-01, -3.5095e-01],\n",
      "          [ 6.1770e-01, -3.3322e-01, -8.6814e-01,  ..., -3.2592e-01,\n",
      "            4.3507e-02,  1.3622e-01],\n",
      "          [-1.6441e-01,  8.2580e-01,  3.6885e-01,  ...,  2.9821e-01,\n",
      "            6.5922e-01,  6.0531e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.8042e-01,  5.5793e-02, -1.0992e-01,  ...,  3.0975e-01,\n",
      "            3.9593e-01, -1.9053e-01],\n",
      "          [-1.1007e+00,  4.7574e-01, -1.8205e-01,  ..., -3.6402e-01,\n",
      "           -6.0452e-01,  3.3439e-01],\n",
      "          [-4.8667e-01,  1.4312e-01,  6.1794e-01,  ...,  6.7597e-01,\n",
      "           -1.0261e+00,  3.4641e-01],\n",
      "          ...,\n",
      "          [ 2.4711e-01,  3.7729e-02,  9.5409e-01,  ...,  1.7658e-01,\n",
      "           -5.1192e-02, -3.9830e-01],\n",
      "          [ 1.4818e-01,  3.1216e-01, -7.5470e-01,  ...,  3.4567e-01,\n",
      "           -1.3339e+00, -4.0232e-01],\n",
      "          [-3.0846e-01,  2.4351e-01,  4.2237e-01,  ...,  5.2646e-01,\n",
      "           -7.7426e-01,  1.1175e-01]],\n",
      "\n",
      "         [[-1.4274e-02,  9.3069e-04,  2.0228e-02,  ...,  5.9618e-01,\n",
      "           -3.4379e-01, -9.0332e-01],\n",
      "          [-8.9903e-01,  8.0769e-02, -5.2879e-01,  ..., -2.9104e-01,\n",
      "           -1.0470e+00, -1.3763e-01],\n",
      "          [-9.4292e-01,  7.9225e-02,  1.5136e-01,  ..., -5.5172e-01,\n",
      "           -8.3699e-01,  6.2929e-01],\n",
      "          ...,\n",
      "          [-8.1300e-01,  7.8664e-01, -1.4685e-01,  ..., -2.0379e-01,\n",
      "            8.4974e-01,  3.2850e-01],\n",
      "          [-1.4951e-01, -2.9386e-01, -7.8272e-01,  ..., -3.6297e-01,\n",
      "           -1.0856e+00, -5.1019e-01],\n",
      "          [-6.9607e-02,  5.2750e-02, -7.0985e-02,  ..., -4.1810e-02,\n",
      "           -7.4283e-01,  4.8744e-01]],\n",
      "\n",
      "         [[-1.7177e-01,  1.3073e-01,  5.2687e-01,  ..., -2.1721e-01,\n",
      "           -5.0861e-01, -8.9823e-01],\n",
      "          [-1.3063e+00, -1.1191e+00, -2.8544e-01,  ...,  9.0334e-01,\n",
      "           -5.2385e-01, -1.1521e-01],\n",
      "          [-4.5314e-01, -7.3991e-01, -1.2634e-01,  ..., -5.2871e-01,\n",
      "           -3.6292e-01, -3.5474e-01],\n",
      "          ...,\n",
      "          [-2.8273e-01,  3.0236e-01, -2.3324e-01,  ...,  8.0606e-02,\n",
      "            6.9244e-01,  2.3703e-02],\n",
      "          [-4.4838e-01, -3.1642e-01,  4.4665e-01,  ...,  6.8404e-01,\n",
      "            1.1538e-01, -3.9166e-01],\n",
      "          [ 4.9263e-02, -1.2802e+00,  2.4269e-01,  ..., -2.3287e-01,\n",
      "           -1.1628e+00, -5.8969e-01]]]])\n",
      "Output from standard convolution:\n",
      "tensor([[[[-4.0380e-01, -3.1406e-01, -4.7838e-01,  ..., -1.5355e-01,\n",
      "            4.0880e-01,  2.2182e-01],\n",
      "          [ 4.4625e-01,  5.9604e-01, -4.1285e-01,  ...,  1.6947e-01,\n",
      "           -6.5281e-03, -8.1054e-01],\n",
      "          [ 3.7832e-01, -1.7156e-01, -4.7183e-02,  ...,  4.3828e-01,\n",
      "           -2.5419e-01,  1.3473e+00],\n",
      "          ...,\n",
      "          [-5.4286e-01,  1.8729e-03,  1.5082e+00,  ..., -4.5478e-01,\n",
      "           -4.7381e-01,  3.9000e-01],\n",
      "          [ 4.4608e-01, -9.0825e-01, -7.6615e-01,  ..., -3.3419e-01,\n",
      "           -7.8931e-01,  7.2388e-02],\n",
      "          [-3.6955e-01,  3.7082e-01,  2.9245e-01,  ...,  6.5912e-01,\n",
      "            2.9895e-01,  2.3225e-01]],\n",
      "\n",
      "         [[ 4.0400e-01, -1.4922e-01,  4.4431e-01,  ...,  4.1689e-01,\n",
      "            2.9981e-01, -7.6605e-01],\n",
      "          [ 8.3809e-01,  5.0024e-01,  1.0052e+00,  ...,  2.5175e-02,\n",
      "           -6.3276e-02,  5.1493e-01],\n",
      "          [-3.4004e-01,  1.3410e+00,  5.6880e-01,  ...,  1.9813e-01,\n",
      "            4.7307e-01,  2.9385e-01],\n",
      "          ...,\n",
      "          [-6.2042e-01,  6.7714e-01,  8.0907e-01,  ..., -2.1155e-01,\n",
      "            4.3821e-01, -8.0160e-02],\n",
      "          [-2.2440e-01,  1.9800e-01, -2.7004e-01,  ...,  8.1119e-01,\n",
      "            3.7719e-01, -7.6588e-01],\n",
      "          [-3.7101e-01,  6.2999e-01,  4.7059e-01,  ...,  3.4798e-01,\n",
      "            5.2222e-01,  2.5050e-01]],\n",
      "\n",
      "         [[-1.1212e-01, -6.2471e-01, -2.5591e-01,  ...,  3.9001e-01,\n",
      "            4.7703e-01, -3.0788e-01],\n",
      "          [ 4.3852e-01,  5.6115e-01,  2.3291e-01,  ..., -8.2766e-01,\n",
      "            7.3046e-01, -1.5826e-01],\n",
      "          [ 3.7738e-01,  6.0093e-01,  1.7431e-01,  ...,  7.0693e-01,\n",
      "            8.0548e-01,  2.9699e-01],\n",
      "          ...,\n",
      "          [ 5.9608e-01,  1.0078e-01,  3.0823e-01,  ..., -5.7602e-01,\n",
      "           -1.1783e-01, -3.5095e-01],\n",
      "          [ 6.1770e-01, -3.3322e-01, -8.6814e-01,  ..., -3.2592e-01,\n",
      "            4.3507e-02,  1.3622e-01],\n",
      "          [-1.6441e-01,  8.2580e-01,  3.6885e-01,  ...,  2.9821e-01,\n",
      "            6.5922e-01,  6.0531e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.8042e-01,  5.5793e-02, -1.0992e-01,  ...,  3.0975e-01,\n",
      "            3.9593e-01, -1.9053e-01],\n",
      "          [-1.1007e+00,  4.7574e-01, -1.8205e-01,  ..., -3.6402e-01,\n",
      "           -6.0452e-01,  3.3439e-01],\n",
      "          [-4.8667e-01,  1.4312e-01,  6.1794e-01,  ...,  6.7597e-01,\n",
      "           -1.0261e+00,  3.4641e-01],\n",
      "          ...,\n",
      "          [ 2.4711e-01,  3.7729e-02,  9.5409e-01,  ...,  1.7658e-01,\n",
      "           -5.1192e-02, -3.9830e-01],\n",
      "          [ 1.4818e-01,  3.1216e-01, -7.5470e-01,  ...,  3.4567e-01,\n",
      "           -1.3339e+00, -4.0232e-01],\n",
      "          [-3.0846e-01,  2.4351e-01,  4.2237e-01,  ...,  5.2646e-01,\n",
      "           -7.7426e-01,  1.1175e-01]],\n",
      "\n",
      "         [[-1.4274e-02,  9.3071e-04,  2.0228e-02,  ...,  5.9618e-01,\n",
      "           -3.4379e-01, -9.0332e-01],\n",
      "          [-8.9903e-01,  8.0769e-02, -5.2879e-01,  ..., -2.9104e-01,\n",
      "           -1.0470e+00, -1.3763e-01],\n",
      "          [-9.4292e-01,  7.9225e-02,  1.5136e-01,  ..., -5.5172e-01,\n",
      "           -8.3699e-01,  6.2929e-01],\n",
      "          ...,\n",
      "          [-8.1300e-01,  7.8664e-01, -1.4685e-01,  ..., -2.0379e-01,\n",
      "            8.4974e-01,  3.2850e-01],\n",
      "          [-1.4951e-01, -2.9386e-01, -7.8272e-01,  ..., -3.6297e-01,\n",
      "           -1.0856e+00, -5.1019e-01],\n",
      "          [-6.9607e-02,  5.2750e-02, -7.0985e-02,  ..., -4.1810e-02,\n",
      "           -7.4283e-01,  4.8744e-01]],\n",
      "\n",
      "         [[-1.7177e-01,  1.3073e-01,  5.2687e-01,  ..., -2.1721e-01,\n",
      "           -5.0861e-01, -8.9823e-01],\n",
      "          [-1.3063e+00, -1.1191e+00, -2.8544e-01,  ...,  9.0334e-01,\n",
      "           -5.2385e-01, -1.1521e-01],\n",
      "          [-4.5314e-01, -7.3991e-01, -1.2634e-01,  ..., -5.2871e-01,\n",
      "           -3.6292e-01, -3.5474e-01],\n",
      "          ...,\n",
      "          [-2.8273e-01,  3.0236e-01, -2.3324e-01,  ...,  8.0606e-02,\n",
      "            6.9244e-01,  2.3703e-02],\n",
      "          [-4.4838e-01, -3.1642e-01,  4.4666e-01,  ...,  6.8404e-01,\n",
      "            1.1538e-01, -3.9166e-01],\n",
      "          [ 4.9263e-02, -1.2802e+00,  2.4269e-01,  ..., -2.3287e-01,\n",
      "           -1.1628e+00, -5.8969e-01]]]])\n",
      "Difference between outputs: tensor(3.5763e-07)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def conv2d_to_matmul(input, conv_layer):\n",
    "\n",
    "\n",
    "    out_channels = conv_layer.out_channels\n",
    "    kernel_size = conv_layer.kernel_size\n",
    "    stride = conv_layer.stride\n",
    "    padding = conv_layer.padding\n",
    "    dilation = conv_layer.dilation\n",
    "\n",
    " \n",
    "    input_unf = F.unfold(input, kernel_size=kernel_size, dilation=dilation, padding=padding, stride=stride)\n",
    "\n",
    "    weight = conv_layer.weight.view(out_channels, -1)\n",
    "\n",
    "\n",
    "    output_unf = weight @ input_unf\n",
    "\n",
    "    if conv_layer.bias is not None:\n",
    "        output_unf += conv_layer.bias.unsqueeze(1)\n",
    "\n",
    "    output_height = (input.size(2) + 2*padding[0] - dilation[0] * (kernel_size[0] - 1) - 1) // stride[0] + 1\n",
    "    output_width = (input.size(3) + 2*padding[1] - dilation[1] * (kernel_size[1] - 1) - 1) // stride[1] + 1\n",
    "    output = output_unf.view(1, out_channels, output_height, output_width)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    input = torch.randn(1, 3, 55, 55)  \n",
    "    conv_layer = nn.Conv2d(in_channels=3, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    output = conv2d_to_matmul(input, conv_layer)\n",
    "\n",
    "\n",
    "    conv_output = conv_layer(input)\n",
    "\n",
    "print(\"Output from matrix multiplication:\")\n",
    "print(output)\n",
    "\n",
    "print(\"Output from standard convolution:\")\n",
    "print(conv_output)\n",
    "\n",
    "\n",
    "print(\"Difference between outputs:\", torch.abs(output - conv_output).max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
